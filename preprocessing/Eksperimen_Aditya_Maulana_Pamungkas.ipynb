{
    "nbformat": 4,
    "nbformat_minor": 0,
    "metadata": {
        "colab": {
            "provenance": [],
            "gpuType": "T4"
        },
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3"
        },
        "language_info": {
            "name": "python"
        },
        "accelerator": "GPU"
    },
    "cells": [
        {
            "cell_type": "markdown",
            "source": [
                "# **1. Perkenalan Dataset**\n",
                "\n",
                "Dokumen ini berisi eksperimen manual untuk dataset Heart Disease."
            ],
            "metadata": {
                "id": "kZLRMFl0JyyQ"
            }
        },
        {
            "cell_type": "markdown",
            "source": [
                "Tahap pertama, Anda harus mencari dan menggunakan dataset dengan ketentuan sebagai berikut:\n",
                "\n",
                "1. **Sumber Dataset**:  \n",
                "   Dataset dapat diperoleh dari berbagai sumber, seperti public repositories (*Kaggle*, *UCI ML Repository*, *Open Data*) atau data primer yang Anda kumpulkan sendiri.\n"
            ],
            "metadata": {
                "id": "hssSDn-5n3HR"
            }
        },
        {
            "cell_type": "markdown",
            "source": [
                "# **2. Import Library**"
            ],
            "metadata": {
                "id": "fKADPWcFKlj3"
            }
        },
        {
            "cell_type": "markdown",
            "source": [
                "Pada tahap ini, Anda perlu mengimpor beberapa pustaka (library) Python yang dibutuhkan untuk analisis data dan pembangunan model machine learning atau deep learning."
            ],
            "metadata": {
                "id": "LgA3ERnVn84N"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "import pandas as pd\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "from sklearn.model_selection import train_test_split\n",
                "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
                "from sklearn.impute import SimpleImputer\n",
                "import os"
            ],
            "metadata": {
                "id": "BlmvjLY9M4Yj"
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "source": [
                "# **3. Memuat Dataset**"
            ],
            "metadata": {
                "id": "f3YIEnAFKrKL"
            }
        },
        {
            "cell_type": "markdown",
            "source": [
                "Pada tahap ini, Anda perlu memuat dataset ke dalam notebook."
            ],
            "metadata": {
                "id": "Ey3ItwTen_7E"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "# Load dataset\n",
                "df = pd.read_csv('../heart_disease_raw/heart_disease.csv')\n",
                "df.head()"
            ],
            "metadata": {
                "id": "GHCGNTyrM5fS"
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "source": [
                "# **4. Exploratory Data Analysis (EDA)**\n",
                "\n",
                "Pada tahap ini, Anda akan melakukan **Exploratory Data Analysis (EDA)** untuk memahami karakteristik dataset."
            ],
            "metadata": {
                "id": "bgZkbJLpK9UR"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "# Info Data\n",
                "print(df.info())\n",
                "\n",
                "# Statistik Deskriptif\n",
                "print(df.describe())\n",
                "\n",
                "# Cek Missing Values\n",
                "print(df.isnull().sum())\n",
                "\n",
                "# Visualisasi Target\n",
                "sns.countplot(x='Heart Disease Status', data=df)\n",
                "plt.title('Distribution of Heart Disease Status')\n",
                "plt.show()\n",
                "\n",
                "# Korelasi Matrix\n",
                "plt.figure(figsize=(12, 8))\n",
                "sns.heatmap(df.corr(numeric_only=True), annot=True, cmap='coolwarm')\n",
                "plt.title('Correlation Matrix')\n",
                "plt.show()"
            ],
            "metadata": {
                "id": "dKeejtvxM6X1"
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "source": [
                "# **5. Data Preprocessing**"
            ],
            "metadata": {
                "id": "cpgHfgnSK3ip"
            }
        },
        {
            "cell_type": "markdown",
            "source": [
                "Pada tahap ini, data preprocessing adalah langkah penting untuk memastikan kualitas data sebelum digunakan dalam model machine learning."
            ],
            "metadata": {
                "id": "COf8KUPXLg5r"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "# 1. Handling Missing Values\n",
                "numeric_features = df.select_dtypes(include=['float64', 'int64']).columns\n",
                "categorical_features = df.select_dtypes(include=['object']).columns\n",
                "\n",
                "# Imputasi Median untuk Numerik\n",
                "imputer_num = SimpleImputer(strategy='median')\n",
                "df[numeric_features] = imputer_num.fit_transform(df[numeric_features])\n",
                "\n",
                "# Imputasi Modus untuk Kategorikal\n",
                "imputer_cat = SimpleImputer(strategy='most_frequent')\n",
                "df[categorical_features] = imputer_cat.fit_transform(df[categorical_features])\n",
                "\n",
                "# 2. Encoding Categorical Data\n",
                "# Manual Mapping for Binary/Ordinal\n",
                "binary_cols = ['Smoking', 'Family Heart Disease', 'Diabetes', 'High Blood Pressure', \n",
                "               'Low HDL Cholesterol', 'High LDL Cholesterol', 'Heart Disease Status']\n",
                "\n",
                "for col in binary_cols:\n",
                "    df[col] = df[col].map({'Yes': 1, 'No': 0})\n",
                "\n",
                "df['Gender'] = df['Gender'].map({'Male': 1, 'Female': 0})\n",
                "\n",
                "ordinal_cols = {'Exercise Habits': ['Low', 'Medium', 'High'],\n",
                "                'Alcohol Consumption': ['None', 'Low', 'Medium', 'High'],\n",
                "                'Stress Level': ['Low', 'Medium', 'High'],\n",
                "                'Sugar Consumption': ['Low', 'Medium', 'High']}\n",
                "\n",
                "for col, order in ordinal_cols.items():\n",
                "    df[col] = df[col].apply(lambda x: order.index(x) if x in order else -1)\n",
                "\n",
                "# 3. Splitting Data\n",
                "X = df.drop('Heart Disease Status', axis=1)\n",
                "y = df['Heart Disease Status']\n",
                "\n",
                "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
                "\n",
                "# 4. Scaling\n",
                "scaler = StandardScaler()\n",
                "X_train_scaled = scaler.fit_transform(X_train)\n",
                "X_test_scaled = scaler.transform(X_test)\n",
                "\n",
                "print(\"Shape X_train:\", X_train_scaled.shape)\n",
                "print(\"Shape X_test:\", X_test_scaled.shape)\n",
                "\n",
                "# Save Preprocessed Data (optional for verification)\n",
                "pd.DataFrame(X_train_scaled, columns=X.columns).join(y_train.reset_index(drop=True)).to_csv('heart_disease_preprocessing/train.csv', index=False)\n",
                "pd.DataFrame(X_test_scaled, columns=X.columns).join(y_test.reset_index(drop=True)).to_csv('heart_disease_preprocessing/test.csv', index=False)"
            ],
            "metadata": {
                "id": "Og8pGV0-iDLz"
            },
            "execution_count": null,
            "outputs": []
        }
    ]
}